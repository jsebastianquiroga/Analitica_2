{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/Analitica_2/blob/main/DL/introduction_2_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron\n",
        "\n",
        "Un perceptrón es un modelo simple de red neuronal artificial que se utiliza para la clasificación binaria. El perceptrón fue desarrollado por Frank Rosenblatt en 1957 y se utiliza para separar los datos en dos clases utilizando una función de activación escalón.\n",
        "\n",
        "Un perceptrón tiene entradas, pesos y un sesgo, y produce una salida binaria en función de la suma ponderada de las entradas multiplicadas por sus respectivos pesos, y una función de activación que compara esta suma con un umbral (el sesgo). Si la suma ponderada es mayor o igual al umbral, el perceptrón activa su salida, que es un 1, y si la suma ponderada es menor que el umbral, la salida es 0.\n",
        "\n",
        "El perceptrón es capaz de aprender mediante el ajuste de los pesos y el sesgo a medida que se presentan datos de entrenamiento. A través del proceso de entrenamiento, el perceptrón se ajusta para producir la salida deseada para cada entrada. El perceptrón puede ser visto como una unidad de procesamiento de entrada-salida simple que toma en cuenta las entradas y produce una salida en función de las conexiones ponderadas.\n",
        "\n",
        "A pesar de su simplicidad, los perceptrones son capaces de resolver problemas linealmente separables y han sido utilizados en una amplia variedad de aplicaciones, incluyendo reconocimiento de patrones, clasificación de imágenes y reconocimiento de caracteres."
      ],
      "metadata": {
        "id": "2u5F1RwgoFe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def perceptron(b, tasa_aprendizaje, w1, w2, x1, x2, y, n_muestras):\n",
        "    cont=0\n",
        "    errores = True\n",
        "    while errores:\n",
        "        errores = False\n",
        "        for i in range(n_muestras):\n",
        "            z = ((x1[i] * w1)+(x2[i] * w2)) + b # calculamos z\n",
        "            #funcion escalón\n",
        "            if z >= 0:\n",
        "                z = 1\n",
        "            else:\n",
        "                z = 0\n",
        "          #verificación del error\n",
        "            if z != y[i]:\n",
        "                errores = True\n",
        "                # calcular errores\n",
        "                error = (y[i] - z)\n",
        "                # ajustar sesgo\n",
        "                b = b + ((tasa_aprendizaje * error))\n",
        "                # ajustar pesos\n",
        "                w1 = w1 + (x1[i] * error * tasa_aprendizaje)\n",
        "                w2 = w2 + (x2[i] * error * tasa_aprendizaje)\n",
        "        cont=cont+1\n",
        "    return w1, w2, b, cont"
      ],
      "metadata": {
        "id": "52u4Ygtznxcn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función perceptron() implementa el algoritmo de entrenamiento del perceptrón simple para resolver un problema de clasificación binaria. Los argumentos de entrada son:</br>\n",
        "\n",
        "b: el valor del sesgo (bias).</br>\n",
        "fac_ap: el factor de aprendizaje (learning rate), que determina el tamaño del paso de ajuste de los pesos y del sesgo en cada iteración del algoritmo.</br>\n",
        "w1 y w2: los pesos correspondientes a las características (features) x1 y x2, respectivamente.</br>\n",
        "x1 y x2: dos vectores que contienen las características de cada muestra de entrada.</br>\n",
        "y: un vector que contiene las etiquetas de las muestras de entrada (0 o 1).</br>\n",
        "n_muestras: el número de muestras de entrenamiento.</br></br>\n",
        "La función utiliza un bucle while que se ejecuta hasta que no haya errores de clasificación en el conjunto de entrenamiento. En cada iteración, se calcula el valor de la función de activación para la muestra de entrada correspondiente (a partir de los pesos y el sesgo actuales) y se compara con la etiqueta real de la muestra. Si hay un error de clasificación, se ajustan los pesos y el sesgo en función del factor de aprendizaje y el error cometido, para tratar de corregir el error en la siguiente iteración.\n",
        "\n",
        "La función devuelve los valores de los pesos y el sesgo finales, así como el número de iteraciones necesarias para entrenar el modelo."
      ],
      "metadata": {
        "id": "FZrWS9E3nbRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "or_or  = {\n",
        "    'x1': [0, 0, 1, 1],\n",
        "    'x2': [0, 1, 0, 1],\n",
        "    'y': [0, 1, 1, 1]\n",
        "}\n",
        "\n",
        "or_df = pd.DataFrame(or_or)\n",
        "\n",
        "\n",
        "#parametros de entrada:\n",
        "b = 0 #bias\n",
        "tasa_aprendizaje = 0.1\n",
        "w1 = 0.001 #peso_1\n",
        "w2 = 1000 #peso_1\n",
        "x1 = or_df[\"x1\"]\n",
        "x2 = or_df[\"x2\"]\n",
        "y = or_df[\"y\"]\n",
        "n_muestras = len(y)\n",
        "\n",
        "\n",
        "w1, w2, b, i  = perceptron(b, tasa_aprendizaje, w1, w2, x1, x2, y, n_muestras)\n",
        "print (\"w1 = \", w1)\n",
        "print (\"w2 = \", w2)\n",
        "print (\"b = \", b)\n",
        "print (\"i = \", i)"
      ],
      "metadata": {
        "id": "_FhYnWJsna_n",
        "outputId": "dd4ac768-22fe-4822-c8e0-6580cfb42352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1 =  0.101\n",
            "w2 =  1000.0\n",
            "b =  -0.1\n",
            "i =  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se prueba el algoritmo:\n",
        "\n",
        "z = x1.copy()\n",
        "for i in x1:\n",
        "    z[i] = ((x1[i]* w1) + (x2[i] * w2)) + b # calculamos z\n",
        "    if z[i] >= 0:\n",
        "        y[i] = 1\n",
        "    else:\n",
        "        y[i] = 0\n",
        "\n",
        "print('Valores_predichos',y.values,) \n",
        "print('Valores_originales', or_df.y.values)\n",
        "print('mismos_valores?: ',y.values==or_df.y.values)"
      ],
      "metadata": {
        "id": "T8lQ4Qgypr5z",
        "outputId": "88e132c8-fe58-4f80-ce4d-092bc74a2098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores_predichos [0 1 1 1]\n",
            "Valores_originales [0 1 1 1]\n",
            "mismos_valores?:  [ True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-7uKeCkqBLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd918554fd86c8fa71df5e97543f72a20c78ad3ae14e3e0b29aa7e96c0f0504e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}